{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Для валидации поделим тренировочный набор на 75% обучающего набора,\n",
    "25% тестового набора. На 75% обучающего набора правильность ~0.93. \n",
    "На остальных 25% accuracy ~0.87. С % категории для тестового набора определилсь верно.\n",
    "\n",
    "Выходной файл: 'result_for_test.csv' с двумя колонками item_id, category_id\n",
    "\n",
    "По иерархии для категорий:\n",
    "                  train_score | accuracy_score \n",
    "низшая иерархия |    0.97          0.949\n",
    "средняя иерархия|    0.96          0.928\n",
    "высшая иерархия |    0.93          0.867\n",
    "\n",
    "Хар-ки машины: Core i5-4460S 2.9GHz 8GB RAM (время обработки)\n",
    "\n",
    "В train_test_split параметр shuffle=False, чтобы обучающие и тестовые данные были \n",
    "одинакового состава при анализе категорий по иерархии.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "print('helloworld')\n",
    "import pandas as pd\n",
    "# импортируем pymorphy2 для морфологического разбора русских слов\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим тренировочный набор\n",
    "data_frame = pd.read_csv('train.csv')\n",
    "#data_frame.info() # пустых значений в датафрейме нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# создаем объект MorphAnalyzer для морфологического разбора слова\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def clean_corpus(document, num=3):\n",
    "    \"\"\" Принимает документ(объявление). Далее очистка и морфологический \n",
    "    разбор.\n",
    "    num = 3 для обработки 'описания(description)' объявления\n",
    "    num = 2 обработка 'заголовка(title)', необходимо оставить также числа\n",
    "    \"\"\"\n",
    "    if num == 3:\n",
    "        document = re.sub(\n",
    "            r'[\\W|?|$|.|!|,|\\d|(|)|{|}|*|+|%|#|@|^|\"|\\'|/|\\t|;|:|_|-]', \n",
    "            r' ', \n",
    "            document)\n",
    "    else:\n",
    "        # оставить числа в названии объявления(важно)\n",
    "        document = re.sub(\n",
    "            r'[\\W|?|$|.|!|,|(|)|{|}|*|+|%|#|@|^|\"|\\'|/|\\t|;|:|_|-]', \n",
    "            r' ', \n",
    "            document)\n",
    "        \n",
    "    # для большей информации по граммемам смотри документацию\n",
    "    # http://pymorphy2.readthedocs.io/en/latest/user/grammemes.html\n",
    "    # постараемся оставить только существительные и прилагательные\n",
    "    # исключив остальные части речи уменьшим шум на данных\n",
    "    \n",
    "    document = [word.lower() for word in document.split() if len(word)>num]\n",
    "    clean_corpus = []\n",
    "    # морфологический разбор слова в документе\n",
    "    for word in document:\n",
    "        m = morph.parse(word.replace('.',''))\n",
    "        if len(m) != 0:\n",
    "            clean_word = m[0]\n",
    "            try:\n",
    "                if clean_word.tag.POS not in ('NUMR', 'PRCL', 'INTJ', 'PREP', \n",
    "                                              'ADVB', 'ADJS', 'CONJ', 'PRED', \n",
    "                                              'VERB', 'INFN', 'PRTF', 'GRND', \n",
    "                                              'COMP'):\n",
    "                    clean_corpus.append(clean_word.normal_form)\n",
    "            except TypeError:\n",
    "                clean_corpus.append(clean_word.word)\n",
    "    # удалим дубликаты\n",
    "    clean_corpus = list(set(clean_corpus))\n",
    "    return ' '.join(clean_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# применим функцию clean_corpus к столбцам description и title датафрейма\n",
    "data_frame['description'] = data_frame['description'].apply(clean_corpus)\n",
    "data_frame['title'] = data_frame['title'].apply(clean_corpus, num=2)\n",
    "print(\"--- %s min ---\" % round(((time.time() - start_time)/60),3))\n",
    "# --- 45.799 min ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_columns(df, new_title, first_col, second_col):\n",
    "    \"\"\" Принимает датафрейм, название для новой колонки,\n",
    "    две колонки для объядинения. Возвращает датафрейм с новой\n",
    "    колонкой.\n",
    "    \"\"\"\n",
    "    df[new_title] = df[first_col].astype(str).str.cat(df[second_col].astype(str), sep=' ')\n",
    "    return df\n",
    "\n",
    "def clean_data(document):\n",
    "    \"\"\" Принимает документ и удаляет дубликаты слов.\n",
    "    Вовзращает строку.\n",
    "    \"\"\"\n",
    "    return ' '.join(list(set(document.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# объединим заголовок, описание и цену в одну колонку\n",
    "combined_data_frame = combine_columns(data_frame, 'title_desc', 'title', 'description')\n",
    "combined_data_frame = combine_columns(combined_data_frame, 'title_desc_price', 'title_desc', 'price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# после объединения необходимо повторно удалить дубликаты из столбца\n",
    "# так как заголовок вместе с описанием могут содержать их\n",
    "combined_data_frame['title_desc_price'] = combined_data_frame['title_desc_price'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы определить правильность на тестовом наборе, попробуем определить\n",
    "# правильность на 75% тренировочного наборе с соответствующими метками\n",
    "# оставшиеся 25% данных с метками объявляются тестовым набором\n",
    "# разделим данные combined_data_frame на 75% и 25%\n",
    "combined_data_frame = data_frame\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data_frame['title_desc_price'], \n",
    "                                                    combined_data_frame['category_id'], \n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделим признаки и обучим модель на 75% тренировочного набора\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "start_time = time.time()\n",
    "# выделение признаков и tf_idf\n",
    "# создадим экземпляр класса TfidfVectorizer и подгоняем fit можель к нашим данным\n",
    "vect = TfidfVectorizer(min_df=5, norm=None).fit(X_train)\n",
    "# получим представление \"мешок слов\"\n",
    "X_data_vect = vect.transform(X_train)\n",
    "# обучение модели\n",
    "# после перекрестной проверки параметров лучшим параметром регуляризации оказалось C=0.01\n",
    "model = LogisticRegression(C=0.01).fit(X_data_vect, y_train)\n",
    "score = model.score(X_data_vect, y_train)\n",
    "end_of_time = round(((time.time() - start_time)/60),3)\n",
    "\n",
    "print(\"--- %s min ---\" % end_of_time)\n",
    "print(\"Правильность на 75% тренировочного набора: {:.2f}\".format(score))\n",
    "# --- 12.127 min ---\n",
    "# Правильность на 75% тренировочного набора: 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим модель на 25% тестового набора и сравним\n",
    "# предсказанные метки с истинными\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_predictions = model.predict(vect.transform(X_test))\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_predictions, y_test)))\n",
    "# Accuracy: 0.862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# прочитаем файл с категориями для анализа по иерархии\n",
    "category_frame = pd.read_csv('category.csv')\n",
    "category_frame['name'] = category_frame['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# заменим category_id в тренировочном наборе согласно иерархии\n",
    "# низшая иерархия(пример): Бытовая электроника, для дома и дачи и т.д.\n",
    "def create_dict(num):\n",
    "    \"\"\" Вернем новую серию для иерархии.\n",
    "    \"\"\"\n",
    "    dictionary = {}\n",
    "    for name, cat_id in zip(category_frame['name'], category_frame['category_id']):\n",
    "        name = name.replace(',','').split('|')\n",
    "        try:\n",
    "            dictionary[cat_id] = name[num]\n",
    "        except IndexError:\n",
    "            dictionary[cat_id] = name[num-1]\n",
    "    \n",
    "    copy_combined_data_frame = combined_data_frame\n",
    "    new_category = {}\n",
    "    new_category['category_id'] = copy_combined_data_frame['category_id']\n",
    "    new_category = new_category['category_id'].map(dictionary)\n",
    "    return new_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# закодируем новые категории\n",
    "class_label = LabelEncoder()\n",
    "# веренеи для каждой категории серию числовых меток согласно иерархии\n",
    "low_level = class_label.fit_transform(create_dict(0))# низшая иерархия: \n",
    "mid_level = class_label.fit_transform(create_dict(1))# средняя иерархия: \n",
    "hight_level = class_label.fit_transform(create_dict(2))# высшая иерархия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим тренировочный набор на данных с категорией по низшкей иерархии\n",
    "X_train_low, X_test_low, y_train_low, y_test_low = train_test_split(combined_data_frame['title_desc_price'], \n",
    "                                                                    low_level,\n",
    "                                                                    shuffle=False)\n",
    "# обучение модели\n",
    "# так как тренировочный набор сохранаятся(shuffle=False) возьмем vect с первой инициализацией\n",
    "model_low = LogisticRegression(C=0.01).fit(X_data_vect, y_train_low)\n",
    "score_low = model_low.score(X_data_vect, y_train_low)\n",
    "y_pred_low = model_low.predict(vect.transform(X_test_low))\n",
    "\n",
    "print(\"Правильность на 75% тренировочного набора: {:.2f}\".format(score_low))\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_pred_low, y_test_low)))\n",
    "# Правильность на 75% тренировочного набора: 0.97\n",
    "# Accuracy: 0.949"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим тренировочный набор на данных с категорией по средней иерархии\n",
    "X_train_mid, X_test_mid, y_train_mid, y_test_mid = train_test_split(combined_data_frame['title_desc_price'], \n",
    "                                                                    mid_level,\n",
    "                                                                    shuffle=False)\n",
    "# обучение модели\n",
    "model_mid = LogisticRegression(C=0.01).fit(X_data_vect, y_train_mid)\n",
    "score_mid = model_mid.score(X_data_vect, y_train_mid)\n",
    "y_pred_mid = model_mid.predict(vect.transform(X_test_mid))\n",
    "\n",
    "print(\"Правильность на 75% тренировочного набора: {:.2f}\".format(score_mid))\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_pred_mid, y_test_mid)))\n",
    "# Правильность на 75% тренировочного набора: 0.96\n",
    "# Accuracy: 0.928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучим тренировочный набор на данных с категорией по средней иерархии\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(combined_data_frame['title_desc_price'], \n",
    "                                                            hight_level,\n",
    "                                                            shuffle=False)\n",
    "# обучение модели\n",
    "model_h = LogisticRegression(C=0.01).fit(X_data_vect, y_train_h)\n",
    "score_h = model_h.score(X_data_vect, y_train_h)\n",
    "y_pred_h = model_h.predict(vect.transform(X_test_h))\n",
    "\n",
    "print(\"Правильность на 75% тренировочного набора: {:.2f}\".format(score_h))\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_pred_h, y_test_h)))\n",
    "# Правильность на 75% тренировочного набора: 0.93\n",
    "# Accuracy: 0.87"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# прочитаем и применим функции очистки и объядинения для тестового набора\n",
    "data_frame_test = pd.read_csv('test.csv')\n",
    "#data_frame_test.info() # пустых значений в датафрейме нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим функцию clean_corpus к столбцам датафрейма\n",
    "data_frame_test['description'] = data_frame_test['description'].apply(clean_corpus)\n",
    "data_frame_test['title'] = data_frame_test['title'].apply(clean_corpus, num=2)\n",
    "# объединим заголовок, описание и цену в одну колонку\n",
    "combined_data_test = combine_columns(data_frame_test, 'title_desc', \n",
    "                                      'title', 'description')\n",
    "combined_data_test = combine_columns(combined_data_test, 'title_desc_price', \n",
    "                                      'title_desc', 'price')\n",
    "# после объединения необходимо повторно удалить дубликаты из столбца\n",
    "# так как заголовок вместе с описанием могут содержать их \n",
    "combined_data_test['title_desc_price'] = combined_data_test['title_desc_price'].apply(clean_data)\n",
    "# предскажем категории для тестовых данных\n",
    "X_test_new = combined_data_test['title_desc_price']\n",
    "test_predictions = model.predict(vect.transform(X_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# запишем в 'result_for_test.csv' предсказанные категории и id объявлений\n",
    "result_test_frame = pd.DataFrame({'category_id':test_predictions, 'item_id':data_frame_test['item_id']})\n",
    "result_test_frame.to_csv('result_for_test.csv')\n",
    "# p.s. при обучении набора на 100% тренировочных данных,\n",
    "# категории будут определены точнее\n",
    "# при визуальном анализе объявлений и предсказанных категорий \n",
    "# практически все кажется верным. Можно уотверждать правильность ~87-88 согласно accuracy%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
